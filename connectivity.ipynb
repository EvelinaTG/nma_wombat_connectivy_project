{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUYpthOiLK1rLwAmnIqAEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgonzal1/nma_wombat_connectivy_project/blob/master/connectivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5E0jLc0DVAC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxau-hjxDYpV",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)\n",
        "\n",
        "\n",
        "\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat, np.load('steinmetz_part%d.npz'%j, allow_pickle=True)['dat']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjRDXhBZJ0Ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@widgets.interact\n",
        "def get_representative_session(min=(0,7)):\n",
        "  \"\"\" To simplify the model we are selecting a session recording with most of the regions represented.\n",
        "    This interactive function help us to decide the session based on the minimal regions represented and number of \n",
        "    total neurons recorded.\n",
        "\n",
        "  \"\"\"\n",
        "  print(\"\")\n",
        "  brain_groups = [[\"VISa\", \"VISam\", \"VISl\", \"VISp\", \"VISpm\", \"VISrl\"], # visual cortex\n",
        "                  [\"CL\", \"LD\", \"LGd\", \"LH\", \"LP\", \"MD\", \"MG\", \"PO\", \"POL\", \"PT\", \"RT\", \"SPF\", \"TH\", \"VAL\", \"VPL\", \"VPM\"], # thalamus\n",
        "                  [\"CA\", \"CA1\", \"CA2\", \"CA3\", \"DG\", \"SUB\", \"POST\"], # hippocampal\n",
        "                  [\"ACA\", \"AUD\", \"COA\", \"DP\", \"ILA\", \"MOp\", \"MOs\", \"OLF\", \"ORB\", \"ORBm\", \"PIR\", \"PL\", \"SSp\", \"SSs\", \"RSP\",\" TT\"], # non-visual cortex\n",
        "                  [\"APN\", \"IC\", \"MB\", \"MRN\", \"NB\", \"PAG\", \"RN\", \"SCs\", \"SCm\", \"SCig\", \"SCsg\", \"ZI\"], # midbrain\n",
        "                  [\"ACB\", \"CP\", \"GPe\", \"LS\", \"LSc\", \"LSr\", \"MS\", \"OT\", \"SNr\", \"SI\"], # basal ganglia \n",
        "                  [\"BLA\", \"BMA\", \"EP\", \"EPd\", \"MEA\"] # cortical subplate\n",
        "                  ]\n",
        "  regions = [\"visual ctx\", \"thal\", \"hipp\", \"non-visual ctx\", \"midbrain\", \"basal ganglia\", \"cortical subplate\"]\n",
        "  for i in range (0,38):\n",
        "    session = alldat[i]\n",
        "    brain_areas = set(session['brain_area'])\n",
        "    representative = []\n",
        "    for group in brain_groups:\n",
        "        representative.append(any(area in brain_areas for area in group))\n",
        "    \n",
        "    if(representative.count(True)>min):\n",
        "      print(\"Session:\" , i, \"Total neurons:\",session['brain_area'].shape[0])\n",
        "      #TODO: Create a nice plot to represent the information\n",
        "      #labels, sizes = np.unique(session['brain_area'], return_counts=True)\n",
        "      #fig = plt.figure()\n",
        "      #ax = fig.add_axes([0,0,1,1])\n",
        "      #ax.bar(regions,representative)\n",
        "      #ax.set_title(\"Session {}\".format(i))\n",
        "      #plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2ajfTQyPLdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_sessions = 39\n",
        "trial_time = 2.5\n",
        "\n",
        "def get_trainning_set():\n",
        "  \"\"\"\n",
        "  Get a subset of alldat for trainning purposes.\n",
        "\n",
        "  Returns:\n",
        "    map: dat['spks']: neurons by trials by time bins. Time bin = 10ms.\n",
        "         dat['brain_area']: brain area for each neuron recorded.\n",
        "         dat['contrast_right']: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "         dat['contrast_left']: contrast level for left stimulus.\n",
        "         dat['response']: which side the response was (-1, 0, 1). Choices for the right stimulus are -1.\n",
        "         dat['response_times']: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and always does!).\n",
        "         dat['wheel']: exact position of the wheel that the mice uses to make a response, binned at 10ms.\n",
        "         dat['pupil']: pupil area (noisy, because pupil is very small).\n",
        "         dat['lfp']: recording of the local field potential in each brain area from this experiment, binned at 10ms.\n",
        "         dat['brain_area_lfp']: brain area names for the LFP channels.\n",
        "  \"\"\"\n",
        "  # Functions to split data and get a subset. If condition of areas  \n",
        "  tranning_set = alldat\n",
        "  return trainning_set\n",
        "\n",
        "def get_validation_set():\n",
        "  \"\"\"\n",
        "  Get a subset of alldat for validation purposes. This should be ~5%-10% of all the data.\n",
        "\n",
        "  Returns:\n",
        "    map: dat['spks']: neurons by trials by time bins. Time bin = 10ms.\n",
        "         dat['brain_area']: brain area for each neuron recorded.\n",
        "         dat['contrast_right']: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "         dat['contrast_left']: contrast level for left stimulus.\n",
        "         dat['response']: which side the response was (-1, 0, 1). Choices for the right stimulus are -1.\n",
        "         dat['response_times']: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and always does!).\n",
        "         dat['wheel']: exact position of the wheel that the mice uses to make a response, binned at 10ms.\n",
        "         dat['pupil']: pupil area (noisy, because pupil is very small).\n",
        "         dat['lfp']: recording of the local field potential in each brain area from this experiment, binned at 10ms.\n",
        "         dat['brain_area_lfp']: brain area names for the LFP channels.\n",
        "  \"\"\"\n",
        "  # Functions to split data and get a subset \n",
        "  validation_set = alldat\n",
        "  return validation_set\n",
        "\n",
        "def get_visual_spikes(data_set):\n",
        "  return\n",
        "\n",
        "def get_motor_spikes(data_set):\n",
        "  return\n",
        "\n",
        "def get_stimulus(data_set):\n",
        "  \"\"\"\n",
        "   Args: \n",
        "      data_set: (map) Subset of alldat\n",
        "      \n",
        "   Returns:\n",
        "      stim_right: (np.array) contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "      stim_left: (np.array) contrast level for left stimulus.\n",
        "  \"\"\"\n",
        "  stim_right = np.array(data_set['contrast_right'])\n",
        "  stim_left  = np.array(data_set['contrast_left'])\n",
        "  return stim_right, stim_left\n",
        "\n",
        "\n",
        "def get_response(data_set):\n",
        "  \"\"\"\n",
        "   Args: \n",
        "      data_set: Subset of alldat\n",
        "\n",
        "   Returns:\n",
        "        np.array: which side the response was (-1, 0, 1). Choices for the right stimulus are -1.\n",
        "  \"\"\"\n",
        "  response =  np.array(data_set['response'])\n",
        "  return response\n",
        "\n",
        "response = get_response(alldat[1])\n",
        "right, left = get_stimulus(alldat[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}